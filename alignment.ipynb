{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==================== ALIGNMENT =====================\n",
    "## compute user alignment and issue alignment based on\n",
    "## previously computed users_blocks.csv\n",
    "## and trend2topic.csv\n",
    "## ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77efb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.cluster import hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_user_alignment_numpy(A1, A2):    \n",
    "    ## find the common indices where both arrays are nonzero\n",
    "    common_indices = np.nonzero((A1 != 0) & (A2 != 0))[0]\n",
    "    \n",
    "    ## count the number of common indices with the same values\n",
    "    same_values_count = np.sum(A1[common_indices] == A2[common_indices])\n",
    "    different_values_count = len(common_indices) - same_values_count\n",
    "    \n",
    "    score = same_values_count-different_values_count\n",
    "    \n",
    "    ## divide the count by the number of common indices\n",
    "    if len(common_indices) > 0:\n",
    "        result = score / len(common_indices)\n",
    "    else:\n",
    "        result = np.nan  ## handle case when there are no common nonzero indices\n",
    "    \n",
    "    return result\n",
    "\n",
    "def hierarchical_clustering(similarity_matrix,N_clusters=2):\n",
    "    distance_matrix = np.nan_to_num(1-similarity_matrix)\n",
    "    Z = hierarchy.linkage(distance_matrix, method='complete')  # You can choose a different linkage method if needed\n",
    "    ## cut the dendrogram to obtain clusters\n",
    "    num_clusters = N_clusters # You can adjust this number as needed\n",
    "    cluster_labels = hierarchy.fcluster(Z, t=num_clusters, criterion='maxclust')\n",
    "    ## rearrange the rows of the matrix based on cluster labels\n",
    "    sorted_indices = np.argsort(cluster_labels)\n",
    "    sorted_matrix = similarity_matrix[np.ix_(sorted_indices,sorted_indices)]\n",
    "    return cluster_labels,sorted_matrix\n",
    "\n",
    "def optimal_leaf_sort(matrix):\n",
    "    distance_matrix = np.nan_to_num(1-matrix)\n",
    "    Z = hierarchy.linkage(distance_matrix, method='complete')  # You can choose a different linkage method if needed    \n",
    "    order = hierarchy.leaves_list(hierarchy.optimal_leaf_ordering(Z, distance_matrix))\n",
    "    return matrix[np.ix_(order,order)],order\n",
    "\n",
    "def compute_ideological_score(utm_user,utm_left,utm_right):\n",
    "    alignment_left = np.apply_along_axis(lambda row: compute_user_alignment_numpy(utm_user, row), 1, utm_left)\n",
    "    alignment_right = np.apply_along_axis(lambda row: compute_user_alignment_numpy(utm_user, row), 1, utm_right)    \n",
    "    alignment_left_mean = np.nanmean(alignment_left)\n",
    "    alignment_right_mean = np.nanmean(alignment_right)    \n",
    "    score = 0.5 * (alignment_right_mean-alignment_left_mean)\n",
    "    return score\n",
    "\n",
    "def print_top_users_of_cluster(cluster_labels,user_indices,sortby='out_degree_total',N=100):\n",
    "    N_clusters = len(set(cluster_labels))\n",
    "    sorted_indices = np.argsort(cluster_labels)\n",
    "    position = 0\n",
    "    for i in np.arange(N_clusters):        \n",
    "        subset = np.where(cluster_labels==i+1)        \n",
    "        N_elements = len(subset[0])        \n",
    "        print(f\"Cluster {i} ({N_elements} users) | {position} - {position+N_elements}\")\n",
    "        print(userdf.loc[user_indices[np.where(cluster_labels==i+1)]].sort_values(by=sortby,ascending=False)['screen_name'][:N])\n",
    "        print()\n",
    "        position += N_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the user cluster assignments\n",
    "userdf = pd.read_csv(\"./output/users_blocks.csv\",dtype={'user_id':str})\n",
    "sbm_stats = pd.read_csv(\"./output/sbm/sbm_stats.csv\")\n",
    "trend2idx = dict(zip(sbm_stats['trend'],sbm_stats.index))\n",
    "N_users = len(userdf)\n",
    "N_trends = len(trend2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add topics\n",
    "trend2topic = pd.read_csv(\"./data/trend2topic.csv\")\n",
    "trend2topic = trend2topic.set_index('trend')\n",
    "sbm_stats['main_topic'] = sbm_stats['trend'].map(trend2topic['main_topic'])\n",
    "topics = sorted(sbm_stats['main_topic'].value_counts().index)\n",
    "N_topics = len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the user-trends-matrix\n",
    "user_trend_mat = np.zeros((N_users,N_trends),dtype=int)\n",
    "for user_idx,row in tqdm(userdf.iterrows(),total=userdf.shape[0]):    \n",
    "    trends = row['trends'].split(\"|\")\n",
    "    blocks = [int(i) for i in row['blocks'].split(\"|\")]\n",
    "    for idx,trend in enumerate(trends):\n",
    "        trend_idx = trend2idx[trend]\n",
    "        block = blocks[idx]\n",
    "        user_trend_mat[user_idx][trend_idx] = block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute pairwise user alignment\n",
    "N_sample = 1000\n",
    "high_id_indices = userdf.sort_values(by=['in_degree_total'],ascending=False)[:N_sample].index\n",
    "high_od_indices = userdf.sort_values(by=['out_degree_total'],ascending=False)[:N_sample].index \n",
    "both_indices = list(set(list(high_id_indices) + list(high_od_indices)))\n",
    "random_indices = userdf[userdf['N_trends_total'] >= 10].sample(N_sample).index\n",
    "\n",
    "results_dict = {'influencers':{'indices':high_id_indices,\n",
    "                               'similarity_matrix':0},\n",
    "                'multipliers':{'indices':high_od_indices,\n",
    "                               'similarity_matrix':0},\n",
    "                'randomusers':{'indices':random_indices,\n",
    "                               'similarity_matrix':0},\n",
    "                'both':{'indices':both_indices,\n",
    "                        'similarity_matrix':0}\n",
    "               }\n",
    "\n",
    "for user_type in tqdm(['influencers','multipliers','randomusers','both']):\n",
    "    indices = results_dict[user_type]['indices']\n",
    "    user_trend_mat_sample = user_trend_mat[indices].copy()\n",
    "    user_alignment_mat = pairwise_distances(user_trend_mat_sample,metric=compute_user_alignment_numpy,n_jobs=1)\n",
    "    results_dict[user_type]['similarity_matrix'] = user_alignment_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23265e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## cluster\n",
    "cl_inf,sm_inf = hierarchical_clustering(results_dict[\"influencers\"]['similarity_matrix'],N_clusters=2)\n",
    "cl_mul,sm_mul = hierarchical_clustering(results_dict[\"multipliers\"]['similarity_matrix'],N_clusters=2)\n",
    "cl_ran,sm_ran = hierarchical_clustering(results_dict[\"randomusers\"]['similarity_matrix'],N_clusters=2)\n",
    "cl_bot,sm_bot = hierarchical_clustering(results_dict[\"both\"]['similarity_matrix'],N_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the clustering right (left/right assignment)\n",
    "## this only makes sense if you know the users...\n",
    "\n",
    "left_influencers_idx = []\n",
    "right_influencers_idx = []\n",
    "indices_influencers = results_dict[\"influencers\"][\"indices\"]\n",
    "left_influencers_idx.extend(indices_influencers[np.where(cl_inf==2)])\n",
    "right_influencers_idx.extend(indices_influencers[np.where(cl_inf==1)])\n",
    "\n",
    "left_multipliers_idx = []\n",
    "right_multipliers_idx = []\n",
    "indices_multipliers = results_dict[\"multipliers\"][\"indices\"]\n",
    "left_multipliers_idx.extend(indices_multipliers[np.where(cl_mul==1)])\n",
    "right_multipliers_idx.extend(indices_multipliers[np.where(cl_mul==2)])\n",
    "\n",
    "left_both_idx = []\n",
    "right_both_idx = []\n",
    "indices_both = np.array(results_dict[\"both\"][\"indices\"])\n",
    "left_both_idx.extend(indices_both[np.where(cl_bot==2)])\n",
    "right_both_idx.extend(indices_both[np.where(cl_bot==1)])\n",
    "\n",
    "results_dict[\"influencers\"][\"left\"] = left_influencers_idx\n",
    "results_dict[\"influencers\"][\"right\"] = right_influencers_idx\n",
    "results_dict[\"multipliers\"][\"left\"] = left_multipliers_idx\n",
    "results_dict[\"multipliers\"][\"right\"] = right_multipliers_idx\n",
    "results_dict[\"both\"][\"left\"] = left_both_idx\n",
    "results_dict[\"both\"][\"right\"] = right_both_idx\n",
    "results_dict[\"both\"][\"left\"] = np.array(results_dict[\"both\"][\"left\"])\n",
    "results_dict[\"both\"][\"right\"] = np.array(results_dict[\"both\"][\"right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the user alignment to each cluster\n",
    "for user_type in ['influencers','multipliers','randomusers']:\n",
    "    \n",
    "    utm_left = user_trend_mat[results_dict[\"both\"][\"left\"]]\n",
    "    utm_right = user_trend_mat[results_dict[\"both\"][\"right\"]]\n",
    "    \n",
    "    user_set = results_dict[user_type]['indices']\n",
    "    user_dict = {}\n",
    "    for user_idx in tqdm(user_set):\n",
    "        utm_user = user_trend_mat[user_idx]\n",
    "        score_global = compute_ideological_score(utm_user,utm_left,utm_right)\n",
    "        ud = {}\n",
    "        ud['user_id'] = userdf.iloc[user_idx]['user_id']\n",
    "        # ud['screen_name'] = userdf.iloc[user_idx]['screen_name']\n",
    "        ud['global_score'] = score_global\n",
    "        for topic in topics:\n",
    "            ## get the indices of the topics\n",
    "            topic_indices = sbm_stats[sbm_stats['main_topic'] == topic].index\n",
    "            utm_user_topic = utm_user[topic_indices]\n",
    "            utm_left_topic = utm_left[:,topic_indices]\n",
    "            utm_right_topic = utm_right[:,topic_indices]\n",
    "            topic_score = compute_ideological_score(utm_user_topic,utm_left_topic,utm_right_topic)\n",
    "            ud[topic] = topic_score\n",
    "        user_dict[user_idx] = ud\n",
    "    alignment = pd.DataFrame(user_dict).T\n",
    "    for t in topics:\n",
    "        alignment[t] = alignment[t].astype(float)\n",
    "    results_dict[user_type]['alignment'] = alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the topic alignment matrix\n",
    "for user_type in ['influencers','multipliers','randomusers']:\n",
    "    alignment = results_dict[user_type]['alignment']\n",
    "    topic_alignment_mat = np.zeros((N_topics,N_topics))\n",
    "    for i in range(N_topics):\n",
    "        for j in range(N_topics):\n",
    "            topic1 = topics[i]\n",
    "            topic2 = topics[j]\n",
    "            topicalignment = np.nanmean(alignment[topic1] * alignment[topic2])\n",
    "            topic_alignment_mat[i][j] = topicalignment        \n",
    "    results_dict[user_type]['topic_alignment_mat'] = topic_alignment_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c84686",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## issue alignment plot (1)\n",
    "columns = ['global_score'] + topics\n",
    "handles = ['Global'] + topics\n",
    "\n",
    "ce = results_dict['influencers']['alignment'].copy()\n",
    "ce = ce.sort_values(by='global_score')\n",
    "utm_influencers = np.array(ce[columns],dtype=float)\n",
    "\n",
    "ce = results_dict['multipliers']['alignment'].copy()\n",
    "ce = ce.sort_values(by='global_score')\n",
    "utm_multipliers = np.array(ce[columns],dtype=float)\n",
    "\n",
    "aspect = .016\n",
    "\n",
    "fig = plt.figure(figsize=(13,6))\n",
    "\n",
    "gs = fig.add_gridspec(1, 3, width_ratios=[1, 1, 0.03], height_ratios=[1])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "pos = ax1.imshow(utm_influencers,aspect=aspect,interpolation='nearest')\n",
    "ax1.set_title(\"Influencers\",loc='left',fontdict={'weight':'bold'})\n",
    "\n",
    "ax1.set_xticks(np.arange(N_topics+1),np.array(handles),rotation=45,ha='right')\n",
    "ax1.set_yticks([])\n",
    "\n",
    "ax2.imshow(utm_multipliers,aspect=aspect,interpolation='nearest')\n",
    "ax2.set_title(\"Multipliers\",loc='left',fontdict={'weight':'bold'})\n",
    "\n",
    "ax2.set_xticks(np.arange(N_topics+1),np.array(handles),rotation=45,ha='right')\n",
    "ax2.set_yticks([])\n",
    "\n",
    "ax1.set_ylabel(\"user index\")\n",
    "\n",
    "cax = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "## add the colorbar\n",
    "cbar = fig.colorbar(pos, cax=cax)\n",
    "cbar.ax.set_aspect(10.3)\n",
    "\n",
    "plt.tight_layout(pad=-1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## issue alignment plot (2)\n",
    "\n",
    "mat1,order1 = optimal_leaf_sort(results_dict['influencers']['topic_alignment_mat'])\n",
    "mat2,order2 = optimal_leaf_sort(results_dict['multipliers']['topic_alignment_mat'])\n",
    "\n",
    "mat1 = np.flip(mat1)\n",
    "order1 = order1[::-1]\n",
    "mat2 = np.flip(mat2)\n",
    "order2 = order2[::-1]\n",
    "\n",
    "vmax = max([np.max(mat1),np.max(mat2)])\n",
    "\n",
    "fig = plt.figure(figsize=(18,8))\n",
    "\n",
    "gs = fig.add_gridspec(1, 3, width_ratios=[1, 1, .03], height_ratios=[1])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "pos = ax1.imshow(mat1,interpolation='nearest',vmin=0,vmax=vmax)\n",
    "ax1.set_title(\"Influencers\",loc='left',fontdict={'weight':'bold'})\n",
    "ax1.set_yticks(np.arange(N_topics),np.array(topics)[order1])\n",
    "ax1.set_xticks(np.arange(N_topics),np.array(topics)[order1],rotation=45,ha='right')\n",
    "\n",
    "pos = ax2.imshow(mat2,interpolation='nearest',vmin=0,vmax=vmax)\n",
    "ax2.set_title(\"Multipliers\",loc='left',fontdict={'weight':'bold'})\n",
    "ax2.set_yticks(np.arange(N_topics),np.array(topics)[order2])\n",
    "ax2.set_xticks(np.arange(N_topics),np.array(topics)[order2],rotation=45,ha='right')\n",
    "cax = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "## add the colorbar\n",
    "cbar = fig.colorbar(pos, cax=cax)\n",
    "\n",
    "fig.tight_layout(h_pad=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8dd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## user alignment plot\n",
    "\n",
    "for user_type in ['influencers','multipliers','randomusers']:\n",
    "    user_idx_order = results_dict[user_type]['alignment'].sort_values(by='global_score').index\n",
    "    user_idx2idx = dict(zip(results_dict[user_type]['indices'],np.arange(1000)))\n",
    "    matrix_order = [user_idx2idx[i] for i in user_idx_order]\n",
    "    matrix = results_dict[user_type]['similarity_matrix']\n",
    "    matrix_ordered = matrix[np.ix_(matrix_order,matrix_order)]\n",
    "    results_dict[user_type]['similarity_matrix_ordered'] = matrix_ordered\n",
    "    \n",
    "mat1 = results_dict['influencers']['similarity_matrix_ordered']\n",
    "mat2 = results_dict['multipliers']['similarity_matrix_ordered']\n",
    "mat3 = results_dict['randomusers']['similarity_matrix_ordered']\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))    \n",
    "\n",
    "gs = fig.add_gridspec(1, 4, width_ratios=[1, 1, 1, 0.03], height_ratios=[1])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "ax1.set_title(\"Influencers\",loc='left',weight='bold')\n",
    "pos = ax1.imshow(mat1,cmap='viridis',interpolation='nearest',rasterized=True)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "ax2.set_title(\"Multipliers\",loc='left',weight='bold')\n",
    "pos = ax2.imshow(mat2,cmap='viridis',interpolation='nearest',rasterized=True)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "\n",
    "ax3.set_title(r\"Random user sample ($N_{trends} \\geq 10$)\",loc='left',weight='bold')\n",
    "pos = ax3.imshow(mat3,cmap='viridis',interpolation='nearest',rasterized=True)\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "ax1.set_ylabel(\"user index\")\n",
    "ax1.set_xlabel(\"user index\")\n",
    "ax2.set_xlabel(\"user index\")\n",
    "ax3.set_xlabel(\"user index\")\n",
    "\n",
    "\n",
    "cax = fig.add_subplot(gs[0, 3])\n",
    "\n",
    "## add the colorbar\n",
    "cbar = fig.colorbar(pos, cax=cax)\n",
    "cbar.ax.set_aspect(16.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef39ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trends",
   "language": "python",
   "name": "trends"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
